---
title: "《Mysql实战45讲》速览"
date: 2020-09-04T13:45:49+08:00
draft: false
categories: ["cs"]
tags: ["数据库"]
keywords: ["Mysql"]
---

## 1. 基础架构：一条SQL查询语句是如何执行的？

![mysql45-01-1](/images/mysql45-01-1.png)

一条查询SQL语句`mysql> select * from T where ID=10；`的执行流程：

1. 客户端将请求打给server层
2. **连接器**负责管理连接，权限验证，检查该客户端是否有执行该SQL权限，有则建立连接并继续
3. 首先看**查询缓存**中是否有，有则返回；
4. 无则将SQL交给**分析器**，对SQL语句进行词法分析、语法分析
5. 继续交给**优化器**，负责执行计划生成，索引选择
6. 继续交给**执行器**，执行器操作**存储引擎**（存储引擎独立于server层，负责存储数据，提供读写接口），返回结果。

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。

- Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
- 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

### 1.1 连接器

跟客户端建立连接、获取权限、维持和管理连接

```shell
mysql -h$ip -P$port -u$user -p
**** # 输入密码
```

连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。

- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。
- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。*之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限*。这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。

建立连接后若没有后续动作，则连接处于空闲状态，使用`show processlist`可看到该链接`Command`列为`Sleep`

空闲太长时间（超过`wait_timeout`（默认8h）），则连接会被连接器断开。

由于建立连接的过程比较复杂，尽量使用长连接。
    - 全使用长连接后，Mysql内存占用涨得很快，因为MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了
    - 解决方法：
        - 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后， 断开连接，之后要查询再重连。
        - 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行`mysql_reset_connection` 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

### 1.2 查询缓存

查询缓存的形式为 <查询语句, 查询结果>。若直接命中，则取缓存结果直接返回。

*不建议使用查询缓存*
    - 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。
    - 对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。

MySQL 也提供了这种“按需使用”的方式。可以将参数 `query_cache_type` 设置成 `DEMAND`，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 `SQL_CACHE` 显式指定，像下面这个语句一样：

```sql
mysql> select SQL_CACHE * from T where ID=10；
```

- MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻
底没有这个功能了。

### 1.3 分析器

MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析
    - 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。
    - “语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法

- 如果语句不对，就会收到“You have an error in your SQL syntax”的错误，一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。

### 1.4 优化器

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。

- 优化器是在表里面有多个索引的时候，决定使用哪个索引
- 或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段

### 1.5 执行器

MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

1. 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。
    - 也就是说：命中查询缓存返回之前、优化器之前会precheck、执行器执行之前 都有做权限检查
2. 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口，扫描*所有可能存在结果的数据行*(对于没索引情况，则是顺序遍历所有行，有索引则是借助索引树遍历所有符合索引条件的行)。 

你会在数据库的慢查询日志中看到一个 `rows_examined` 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此*引擎扫描行数跟`rows_examined` 并不是完全相同的*。

### 提问

如果表 T 中没有字段 k，而你执行了这个语句 select * from T
where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？

*A: 分析器。在分析阶段判断语句是否正确，表是否存在，列是否存在等*

## 2. 日志系统：一条SQL更新语句是如何执行的？

考虑更新语句如下：

```sql
// ID主键， c整型
mysql> update T set c=c+1 where ID=2;
```

更新语句和查询语句一样需要经过“连接器->分析器->优化器->执行器”，但还涉及两个重要的日志模块：**redo log（重做日志）和 binlog（归档日志）**

- 别忘了，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空

### 2.1 redo log

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。

因此，Mysql采用**WAL（Write-Ahead Log）**技术。**先写日志，再写磁盘**。 

**InnoDB有redolog。（换句话说redolog是InnoDB特有的日志）**

具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![mysql45-02-1](/images/mysql45-02-1.png)

- write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

- write pos 和 checkpoint 之间的是还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示四个redolog没有可写的位置，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
- 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。或者叫CFT（Crash Fault Tolerant, 崩溃容错）

### 2.2 binlog

**binlog 是Mysql Server层的日志， 称归档日志**。Mysql一开始只有binlog，不支持崩溃安全，后来InnoDB使用redolog实现崩溃安全。

binlog与redolog的区别：
1. redolog是InnoDB特有；binlog为server层实现，所有引擎均可使用
2. redolog是物理逻辑，记录**“在某个数据页上做了什么修改”**；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1”
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 

### 2.3 考虑redolog和binlog的更新语句流程

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

![mysql45-02-2](/images/mysql45-02-2.png)

- 注意：写redolog拆分成两步（两阶段提交）：实际写并标记prepare -> 执行器提交事务后引擎将状态更新为commit

### 2.4 两阶段提交

如果redolog不使用**两阶段提交**， 那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
- 误操作之后需要根据日志恢复Mysql
- 扩容（常见做法是全量备份加应用binlog）也需要。扩容时如果不是两阶段提交，会导致线上主从数据库不一致

```
由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设 执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？

1. 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。

2. 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。
```

redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### 建议

- redo log 用于保证 crash-safe 能力。`innodb_flush_log_at_trx_commit` 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。

- `sync_binlog` 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

### 提问

1. 如果要实现 “MySQL 可以恢复到半个月内任意一秒的状态”， 怎么操作？

```
A: 

前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。

当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

    1. 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
    2. 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。
```

2. 定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

```
A:

一天一备 “最长恢复时间”更短。 
一天一备情况下最坏情况下需要应用一天的binlog。 而一周一备最坏情况下需要应用一周的binlog，“RTO”（恢复目标时间）更长

而 更频繁的全量备份 也意味着 需要更多存储空间
```

## 3. 事务隔离：为什么你改了我还看不见？

**事务就是要保证一组数据库操作，要么全部成功，要么全部失败。** 在 MySQL 中，事务支持是*在引擎层实现*的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。

### 3.1 隔离性与隔离级别

- 事务 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、**隔离性**、持久性）
    - 上一节提到的redolog和binlog保证了事务的持久性
- 多个事务同时执行的时候，就可能出现**脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）**的问题，为了解决这些问题，就有了“隔离级别”的概念。

SQL 标准的事务隔离级别：

- **读未提交**（read uncommitted）。 是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- **读提交**（read committed）。 是指，一个事务提交之后，它做的变更才会被其他事务看到。
- **可重复读**repeatable read）。 是指，一个事务执行过程中看到的数据，总是**跟这个事务在启动时看到的数据是一致的**。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- **串行化**（serializable ）。顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当**出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成**，才能继续执行

其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。

```sql
mysql> create table T(c int) engine=InnoDB;
insert into T(c) values(1);
```

![mysql45-03-1](/images/mysql45-03-1.png)

- 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。
- 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。
- 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
- 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。

在实现上，数据库里面会创建一个**视图**，访问的时候以视图的逻辑结果为准。**在“可重复读”隔离级别下，这个视图是在事务启动时创建的**，整个事务存在期间都用这个视图。**在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的**。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

配置事务隔离级别的方法：配置启动参数 `transaction-isolation`

哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。

### 3.2 事务隔离的实现

读未提交和串行化实现没啥好讲的，一个是不作为，一个是加锁。

读未提交和可重复读都依赖于**视图**这个概念和**undo log**(回滚日志)

下面讲可重复读。

在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![mysql45-03-2](/images/mysql45-03-2.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

**回滚日志何时删除？**
- 在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。

**为什么尽量不使用长事务？**
- 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
- 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。（这与mysql表数据存储方式有关）
- 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库

### 3.3 事务的启动方式

MySQL 的事务启动方式有以下几种：
- 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
- set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
    - 些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。

建议：
- 总是使用 set autocommit=1, 通过显式语句的方式来启动事务  
- 对于需要频繁使用事务的业务，如果顾虑每次开启事务主动执行“begin”带来的交互次数，可以使用 `commit work and chain` 语法。
    - 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

长事务的查询：
- 可以在 information_schema 库的 innodb_trx 这个表（里边放的是还没提交的事务）中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。
```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

### 提问

系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？

```
A: 
这个问题，我们可以从应用开发端和数据库端来看。

首先，从应用开发端来看：
1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）

其次，从数据库端来看：
1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
2. Percona 的 pt-kill 这个工具不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。
```

## 4. 深入浅出索引（上）

- 索引是数据库系统里面最重要的概念之一
- 索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

### 4.1 索引的常见模型

- 哈希表：
    - 哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。
- 有序数组：
    - 有序数组在等值查询和范围查询场景中的性能就都非常优秀
    - 更新数据时维护成本太高，只适合静态存储引擎
- 搜索树
    - 各项操作性能都较高
    - 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。
    - 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。
如今，跳表、B+树、LSM树等用的比较多

### 4.2 InnoDB索引模型

- 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为**索引组织表**。
- **B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数**。
- InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。
- 每一个索引在 InnoDB 里面对应一棵 B+ 树。
- 根据叶子节点的内容，索引类型分为**主键索引**和**非主键索引**。
    - 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为**聚簇索引**（clustered index）。
    - 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为**二级索引**（secondary index）。
    - 普通索引查询时 须先在普通索引数中查询到对应主键，再根据主键到主键索引树查询到数据行，这个过程叫**回表**
    - 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 4.3 B+树索引维护

- B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护
- 插入数据时，若数据页已满，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂**。
    - 页分裂导致插入性能下降
    - 页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。
- 当相邻两个页由于删除了数据，利用率很低之后，会将数据页做**页合并**。合并的过程，可以认为是分裂过程的逆过程。

### 4.4 讨论：什么场景下适合使用自增主键

- **自增主键**是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT
    - 插入新记录时可以不指定ID，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。
    - 性能上：
        - 自增主键的插入数据模式，正符合了**递增插入**的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也**不会触发叶子节点的分裂**。
        - 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。
    - 存储空间：
        - 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。
        - 举例：假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，使用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用自增整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。
    - 从性能和存储空间方面考量，**自增主键*往往*是更合理的选择**。    
    - *对于典型的KV场景（只有一个索引；该索引必须是唯一索引），由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。*

### 提问

为表T重建索引时，会遇到两种：
1. 重建普通索引k
```sql
alter table T drop index k;
alter table T add index(k);
```
2. 重建主键索引id
```sql
alter table T drop primary key;
alter table T add primary key(id);
```
对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

```
A:
重建索引 k 的做法是合理的，可以达到省空间的目的。
但是，重建主键的过程不合理。
不论是删除主键还是创建主键，都会将整个表重建。
所以连着执行这两个语句的话，第一个语句就白做了。
这两个语句，你可以用这个语句代替 ： 
alter table T engine=InnoDB。

ps: 
为什么要重建索引?
    索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。
```

## 5. 深入浅出索引（下）

### 5.1 一条查询语句的执行流程（索引树中）

考虑表（主键ID，普通索引k）：

![mysql45-05-1](/images/mysql45-05-1.png)

执行`select * from T where k between 3 and 5`， 流程为：

1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
2. 再到 ID 索引树查到 ID=300 对应的 R3；
3. 在 k 索引树取下一个值 k=5，取得 ID=500；
4. 再回到 ID 索引树查到 ID=500 对应的 R4；
5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。

共在k树查了3次，回表了2次。

在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？

### 5.2 覆盖索引

- 如果执行的语句是 `select ID from T where k between 3 and 5`，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。
- **由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段**。

给出执行`select ID from T where k between 3 and 5`的流程：
1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
2. 在 k 索引树取下一个值 k=5，取得 ID=500；
3. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。

可见在k索引树读了三次，而不必再回表。
    - 注意：虽然在k树读了三次，但对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2

讨论：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？
- 如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

### 5.3 最左前缀原则

**B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。**

不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。

利用索引的“最左前缀”，有什么好处？
- 假设有name, age两个字段，但是有三个高频查询（不高频不一定需要建立索引），一个是按name查；一个是按age查；一个是按name和age查（先查name再查age）
- 不考虑“最左前缀”，就需要建立三个索引：index(name)、index(age)、index(name, age)
- 考虑“最左前缀”，由于联合索引index(name, age)是从左向右匹配的，所以可以替代掉index(name)，因此只需要建立两个索引：index(age)、index(name, age)。 
- 联合索引中字段的顺序也要考虑。如果只有两个高频请求（一个是按name查；一个是按name和age查（先查name再查age））。联合索引可以是index(name, age)，也可以是index(age, name)，但选前者的话，可以不用建立索引index(name)，自然是更好的。**在建立联合索引的时候，如何安排索引内的字段顺序？ 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**
- 如果继续考虑上面的那三个高频请求，那么两种索引组合：`[index(name)，index(name,age)]`和`[index(age)，index(age,name)]`哪个更好呢？**调整顺序无法减少索引数时，选择索引空间占用更小的方案**，由于name字段比age字段大，选后者

### 5.4 索引下推

MySQL 5.6 引入**索引下推优化**（index condition pushdown)， 可以**在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录**，减少回表次数。

在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。

举例：
- 联合索引index(name, age)，现在要查*姓张的、10岁的*所有结果。
    - 没有索引下推优化时，只能按“最左前缀”原则在索引树上找到所有*姓张的*主键ID，再回表去判断这些记录哪些是*10岁的*。
    - 有索引下推优化时，在index(name,age)索引树时就会直接对*姓张的*索引节点检查是否*10岁的*。减少了回表次数

### 5.5 总结

在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。

### 提问

