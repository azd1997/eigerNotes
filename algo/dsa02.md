---
title: "数据结构与算法（2）——数组"
date: 2019-09-26T22:05:29+08:00
draft: false
categories: ["algo"]
tags: ["数据结构"]
keywords: ["数组"]
---

## 1. 导语

**为什么数组下表从0开始而非1开始？**

## 2. 如何实现随机访问

**数组(array)** 是一种**线性表**数据结构，用一组**连续**的内存空间，存储一组**相同类型**的数据。

1. **线性表:** 数据排成一条线一样的结构，每个线性表上的数据只有前后两个方向。典型的线性表结构有：数组、链表、队列、栈。与线性表相对应的是**非线性表**，如二叉树、堆、图等，它们的数据之间不是简单的前后关系。
   ![dsa02-1](/images/dsa02-1.jpg)
   ![dsa02-2](/images/dsa02-2.jpg)

2. **连续内存空间与相同类型数据：** 这两个限制使得数组可以实现**随机访问**。当然，这两个限制使得数组的一些操作变得非常低效：比如说删除、插入操作，需要做大量的数据搬移工作。

**数组随机访问的原理：**

计算机为每个内存单元分配地址，并根据地址访问内存单元存储的数据。也就是说如果能知道数据的内存地址，那么就可以直接访问该数据。对于数组，其内存寻址公式为：

```go
a[i]_address = base_address + i * data_type_size
```

例如，java中新建一个整型数组`int[] a = new int[10]`，假设说为数组a分配了首地址为1000的连续内存，那么这段内存空间的尾地址就是1000 + 10 × 4 - 1 = 1039，也可以是1000 + 9 × 4 + 3 = 1039。这里显然，如果内存空间不连续，类型不相同（单个数据内存长度不等），那么就没办法像这个公式一样能快速计算内存地址，也就没办法随机访问。

![dsa02-3](/images/dsa02-3.jpg)

**易错问题:**

说法： 链表适合插入、删除，时间复杂度O(1); 数组适合查找，查找时间复杂度O(1)。

纠正：数组适合查找，但即便是排好序的数组，使用二分查找来查找的时间复杂度也是O(logn)。正确的说法是，*数组支持随机访问，根据下表随机访问的时间复杂度是O(1)*。

## 3. 低效的插入与删除

1. 插入

   对于长度为n（或者说数据规模为n）的数组，插入某一个元素，最好情况是在尾部追加，复杂度O(1);最坏情况是插入到头部，其后所有数据都需要顺次往后移一位，时间复杂度O(n)；平均复杂度为(1+...+n)/n = (n+1)/2，为O(n)。

   如果数组数据是有序的，那么插入新数据时必须是后面数据顺次后移，时间复杂度就是O(n);

   但如果数组数据不要求有序。那么插入第k个位置元素，可以**直接将原数据搬至数组尾部，再插入元素**，这样时间复杂度也是O(1)。

   ![dsa02-4](/images/dsa02-4.jpg)

   这个思路在**快速排序**中也有用到

2. 删除

   删除操作和插入类似，为了保证数据连续性后续数据需要顺次前移。时间复杂度也是O(n)。

   在某些情形下，如果不那么追求数据的内存的连续性，选择**将多个待删除数据同时删除，是不是就避免后续数据的多次前移**？

   例如数据`a,b,c,d,e,f,g`，假如要先后删除`a,b,c`三个元素，那么后续元素总共需要搬运6+5+4 = 15次，但是如果同时删除，那么只需要搬运4次（`d,e,f,g`直接前移三个位置）。

   每一次删除操作时，可以对待删除数据进行标记，也就是先后标记`a,b,c`为删除数据，但其实并没有真正删掉。只是从编程语言使用层面访问不到。假如说数组长度为7，现在想再添加一个数据，那么数组空间是不够的，此时会同时执行`a,b,c`三个数据的真正内存删除操作。

   这也正是**JVM标记清除垃圾回收算法**的核心思想。

## 4. 警惕数组越界访问

考虑如下例子：

```c
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){   // i<=3终止条件写错，应该是i<3
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}

// 执行结果： 无限打印“hello world”
```

在C语言中只要不是访问受限的内存，都是可以通过内存地址访问到的。在这个例子中循环到`i=3`时`arr[3]`会指向内存空间中首地址为 arr_base_address + 3 * 4 的4byte空间。

而由于函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。另外一点是：跟编译器分配内存和字节对齐有关 数组3个元素 加上一个变量a 。4个整数刚好能满足8字节对齐 所以i的地址恰好跟着a2后面 导致死循环。。如果数组本身有4个元素 则这里不会出现死循环。。因为编译器64位操作系统下 默认会进行8字节对齐 变量i的地址就不紧跟着数组后面了。

这就导致`arr[3]=0`实际是`i=0`，所以程序陷入了无限循环。

数组越界在C语言中是一种未决行为，并没有规定数组访问越界时编译器如何处理。只要数组通过偏移公式得到的内存地址可用，那么编译器就很可能不报任何错误。很多计算机病毒也正是利用这一点来进行攻击

一些高级语言如java、go，会对内存越界作检查并抛出相应异常。

## 5. 容器能否完全替代数组

在java中为数组提供了ArrayList容器类（很多其他语言也有，比如说C++ STL的Vector类），ArrayList容器类的两大好处：

- **封装了很多数组操作的方法细节，比如删除元素等**
- **支持动态扩容**

动态扩容的原理其实就是在结构体里封装一个底层数组，当底层数组满时为其另分配一个1.5倍大小的内存空间，并将数据搬移过去。

因此，当容器发生扩容时涉及内存申请和数据搬移，比较耗时，最好能提前知道数据规模，在**创建数组容器时指定大小以避免扩容**

在选用容器还是数组时考虑一下几点：

1. Java ArrayList无法存储基本类型int、long等，需要封装为Integer、Long类，而Autoboxing和Unboxing的过程有一定性能损耗，如果特别关注性能，比如说网络框架开发这类偏底层的开发，选择原生数组。当然，一般的业务开发，使用容器类会更方便。或者想使用基本数据类型，也使用原生数组。
2. 如果数据大小事先已知，且需要用到的操作也比较简单，也可以选用原生数组
3. 表示多维数组时，原生数组会更直观一些`Object[][] array`。容器数组则是`ArrayList<ArrayList> array`

## 6. 数组下标为什么从0开始

数组下标从0开始和从1开始相比，在计算偏移量时节省了一次CPU的加法运算。

更主要的是历史原因，C语言这么搞，后来者（其他的高级语言）为了减少C语言使用者的学习成本，也这么设计了。

## 思考

1. JVM标记清除垃圾回收算法

    大多数主流虚拟机采用**可达性分析算法**来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

    不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

2. 二维数组寻址公式

    对于`m*n`的数组，`a[i][j] (i<m,j<n)`的地址为：

    `address = base_address + (i*n+j) * type_size`
