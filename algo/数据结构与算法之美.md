---
title: "《数据结构与算法之美》速览"
date: 2020-09-03T16:34:12+08:00
draft: false
categories: ["算法"]
tags: ["数据结构","算法"]
keywords: ["数据结构", "算法"]
---

## 1. 时间复杂度与空间复杂度

### 知识点

- 大$O$表示法  $O(f(n))$
- 时间复杂度分析
    - 只关注循环执行次数最多的一段代码
    - 加法法则：总复杂度等于量级最大的那段代码的复杂度
    - 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
- 常见时间复杂度：O(1)/O(n)/O(logn)/O(nlogn)/O(m+n)/O(m*n)
- 时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系
- 空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系
- 最好时间复杂度/最坏时间复杂度/平均时间复杂度/均摊时间复杂度(摊还分析)

### 练习

递推公式

```
T(n)=1, n=1
T(n)=4T(n/2)+n, n>1
```
的时间复杂度为:

```
O(n^2)
参考: https://www.nowcoder.com/test/question/done?tid=36925642&qid=305020#summary

递推得：
T(n) = 4^k * T(n/2^k) + k*n
终止条件为T(n/2^k) = T(1)， 也即n=2^k，代回去得：
T(n) = n^2 * T(1) + logn *n 
所以，时间复杂度为: O(n^2)
```

## 2. 数组

- 线性表结构代表
- 支持随机访问
- 插(O(n))/追加(O(1))/删(O(n))/改查(按下标则是O(1)，按值则是O(n))
- 优化
    - 插入：预分配空间
    - 删除：标记删除，而非真正删除。（空闲时批量整理）
- 警惕数组越界：C语言不会检查下标越界
- 下标从0开始：
    - 减少一次求地址的减法运算
    - 历史原因（C这么搞，后来者模仿）    

## 3. 链表

- 经典应用场景：缓存
    - 缓存淘汰策略：LRU(最近最少使用)/LFU(最少使用)/FIFO(先进先出)
- 单链表
- 循环链表
    - 约瑟夫环问题
- 双向链表
- 双向循环链表
- 插入(O(1))/删除(O(1))/改(O(1))/查(O(n))
- 实现链表的注意点：
    - 理解指针/引用的含义
    - 警惕指针丢失(注意操作顺序)和内存泄漏(删除节点后手动释放内存)
    - 利用哨兵节点简化实现难度
    - 重点留意边界情况处理
        - 链表空
        - 链表只有1个节点
        - 链表只有两个节点
        - 处理到链表头结点和尾节点时
        - ...
    - 举例画图，辅助思考
    - 多写多练
        - 单链表反转
        - 链表中环检测
        - 有序链表合并
        - 删除链表倒数第n个节点
        - 求链表的中间节点

## 4. 栈

- 典型应用： 
    - 浏览器的前进后退（两个栈，倒来倒去）
    - 函数调用栈
    - 计算器（表达式求值）
    - 括号匹配
    - 两个栈实现队列
    - 共享一个数组内存的两个栈（两端向内增长）
- 先进后出
- 顺序栈（数组实现）； 链式栈（链表实现）
- 动态扩容的数组栈
- 栈与操作系统中堆栈的区别：操作系统中堆与栈并不是真的堆、栈结构，都只是内存空间的两块线性空间

## 5. 队列

- 典型应用： 有限资源池
- 先进先出
- 顺序队列、链式队列
- 基于数组的循环队列
    - 抽象成环形
    - 浪费一个空间
    - 队列满：head = tail 
    - 队列空：(tail + 1) % n = head。 （这里n是实际数组长度，而不是可用长度）
- 阻塞队列： 生产者-消费者
- 并发队列
    - 加锁实现
    - 无锁实现
        - CAS（Compare And Swap）。入队前获取tail位置，入队时比较tail是否发生变化，否则入队，是则入队失败。 相应地，出队则是获取head位置及比较
        - 类似于Disruptor，利用申请批量内存的操作系统锁实现并发安全，用户程序中不需要锁

## 6. 递归

- 递归是一种非常重要的编程技巧
- 递归需要满足的三个条件
    - 问题可分解为若干个子问题
    - 问题与其分解后的子问题除了数据规模不同，求解思路完全一致
    - 存在递归终止条件
- 编写递归代码的关键： 抽象成递推公式，确定终止条件
- 递归要警惕堆栈溢出
    - linux 32位系统默认给每个进程分配的栈空间为8M
    - 修改成迭代版本，使用自建的栈替代函数调用栈，效率更高
- 警惕重复计算
    - 使用备忘录优化
- 对于规模很大、递归很深的递归，很难单步调试，此时可以：
    - 打印日志，包括递归中的某些变量
    - 结合条件断点进行调试

## 7. 排序

|排序算法|时间复杂度|是否基于比较||:---:|:---:|:---:|
|冒泡、插入、选择|$O(n^2)$|是|
|快排、归并、堆排序|$O(nlogn)$|是|
|桶、计数、基数|$O(n)$|否|

### 7.1 分析排序算法

1. 执行效率
    - 最好时间复杂度/最坏/平均。 与原始序列的有序程度有关
    - 时间复杂度的系数、常数、低阶。 数据规模较小时，要把系数等考虑进来
    - 比较次数和交换(移动)次数。 对于基于比较的排序算法，要把这两项考虑进去
2. 内存消耗
    - 是否原地排序
3. 稳定性
    - 两个值相等的元素排序前后相对位置不变

### 7.2 冒泡排序

每一轮都对相邻的两个元素进行比较并将大的元素交换到右边的位置。这个过程就是“冒泡”。当某一轮遍历数组发现不存在交换，那么说明排序好了

- 原地、稳定
- 逆序度 = 满有序度(n*(n-1)/2) - 有序度

### 7.3 选择排序

数组左半边看作有序区间，右边为待排序区间，在待排序区间选最小值，与有序区间后一位进行交换。这就是“选择”。最终数组整个变为有序区间

- 原地、不稳定

### 7.4 插入排序

数组左边为有序区间，将当前元素（有序区间后一位）放到有序区间，从右到左进行比较交换，直至其放到有序区间正确的位置，不再发生交换。这就是“插入”。当数组最后一个元素都插入到有序区间中的正确位置后，排序完成。

- 原地、稳定
- 在冒泡、选择、插入三者中，插入排序是性能最好的，最主要的原因是插入排序可以使用赋值替代交换（一次交换相当于三次赋值），而冒泡不行。

### 7.5 归并排序

递归实现较易。对于当前数组区间，先一分为二，再递归，归来时左右两个数组都是有序的，只需要使用双指针法合并两个有序数组，则当前数组区间排序完成。

- 非原地、稳定
- 时间复杂度推导

```
递推公式
T(n)=C, n=1
T(n)=2T(n/2)+n, n>1

递推得：
T(n) = 2^k * T(n/2^k) + k*n
终止条件为T(n/2^k) = T(1)， 也即n=2^k，代回去得：
T(n) = n * T(1) + logn *n 
所以，时间复杂度为: O(nlogn)
```

- 空间复杂度O(n)

### 7.6 快速排序

对于当前待排序数组区间，选择一个元素作为基准元素，将区间内小于基准的元素放到基准左侧，大于的放到基准右侧。这样一轮结束后，基准元素就放置到了该放的位置，返回该索引，区间按其分割为两部分，继续递归

- 优化
    - 数组长度很小时，插入排序优化；数组长度规模较小，使用归并排序优化
    - 随机化选取基准元素；或者左中右三数取中间值（甚至五数取中，...）
    - 双路快排：与基准元素相等的元素被较均匀地分散到基准元素的两边。 左右双指针向内移动
    - 三路快排：与基准元素相等的元素都被放置到该放的位置，返回基准元素区间左右边界。左右双指针加中间一指针。
- 原地、不稳定    

### 7.7 线性排序

桶排序、基数排序、计数排序。O(n)

### 7.8 桶排序

将n个数据遍历一遍，分到m个**有序的桶**（桶之间天然有序）中，再在各个桶内进行排序，最后将各个桶的数据取出，组合在一起，排序完成。

- 时间复杂度O(n*log(n/m))，当n/m不太大时，可认为复杂度O(n)
- 使用条件苛刻：
    - 能容易地分到m个桶，且桶之间天然有序
    - 数据在各个桶的分布较为均匀
- 典型例子：
    - 对交易金额在[1,50]的交易金额数组进行排序，可以划分为[1,10], [11,20], ...等桶
- 适合作为外部排序
    - 例如： 交易金额数组存在一个非常大的文件时，而我们知道交易金额区间，就可以按照交易金额区间划分桶，将数据分到多个桶（文件）中，再加载单个桶到内存中进行内排序。
        - 针对特别大的桶，可以继续划分更细小的桶。    

### 7.9 计数排序

计数排序是特殊的桶排序。其单个桶的表示范围为一个数，而非一个区间。并且记录该数的出现次数（这样可以将空间占用降低到O(k)，k为区间范围大小,通过计数也可以推算出数据应放位置），最后直接组合起来，即排序完成。

- 典型例子：
    - 对交易金额在[1,50]的交易金额数组进行排序，可以划分为1,2,...,50共50个桶.
- 适用范围：
    - 数据范围k不大
    - 数据只适合非负整数（或者是能不改变相对大小情况下转换为非负整数的）

### 7.10 基数排序

以手机号排序举例。手机号有11位，范围太大，不适宜使用计数排序和桶排序。

但是有个特点：当两个手机号第k位大小比较好了之后，第k+1位的比较不影响两个手机号的顺序，或者说不必再比

那么可以对手机号从最低位到最高位按位排序。对每一位的排序必需使用计数排序或桶排序。当最高位也排序好之后，整体排序完成。

时间复杂度为O(k * n)，k为每个元素的位数

- 元素长度不一时，可以考虑补齐至最长长度
- 元素必需能分割出“位”，且位之间有递进的关系。高位比较完后可以不用比较低位
- 每一位的数据范围不大，必须使用线性排序，否则基数排序做不到O(n)

### 练习

- 100万用户按年龄排序
- 100万学生按成绩排序
- 将类似于“DaFB12c3”的字符串进行整理，小写字母在前面，数字在中间，大写字母在后面，但是小写字母之间、数字之间、大写字母之间不要求有序。可以不使用排序完成这个整理吗？

### 具体实现

<https://eiger.me/post/algo/sort/>

## 8. 二分查找

- 时间复杂度O(logn)
- 依赖于顺序表结构（数组）的按下标访问（随机访问）。 （有序链表想二分查找复杂度较高，但是可以借助跳表实现）
- 针对有序数组
- 数据量太小或太大都不适合二分查找
- 实现时不要拘泥于模板，重点注意：
    - 终止条件是什么
    - 终止时`l`和`r`处于什么状态
    - 如何取`mid`
    - `mid`与目标值比较之后，该往哪个区间继续搜索，这个区间的边界情况
- 三类问题
    - 数组中找目标值的位置
    - 找目标值(区间)的左边界
    - 找右边界
- 具体实现见 <https://eiger.me/post/algo/binary-search-problems/>

## 9. 跳表

跳表就是在有序链表基础上构建了多级索引。

比如：原始链表每隔两个节点就构建一个一级索引链表节点，一级索引链表较长还可以继续往上构建二级索引，...

- 时间复杂度 O(3logn)。 3代表每一级索引上最多只需要遍历3个节点
- 跳表内存占用 O(n)
    - 每隔2隔节点构建一个索引节点，可以变成每隔3（这样空间占用少一半了已经），使得索引间隔更稀疏，但时间复杂度差别不大
    - 对于实际应用原始链表存的都是大对象，构建索引占用的内存相比之下并不重要
- 插入操作。O(logn)定位到插入位置，再直接插入
- 删除操作。需要获取删除节点的前驱节点，最好使用双链表
- 跳表索引的动态更新。 
    - 前面讲的插入操作会导致可能两相邻索引之间的原始链表部分长度过长，使得跳表退化成链表。    
    - 可以在插入数据时随机选择k值，在1~k级索引中也加入待加入数据节点。
    - 也就是说，跳表依赖随机函数来维护“平衡性”，避免复杂度退化
- Redis使用跳表实现有序集合

## 10. 散列表

- 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。
- 键 -> (hash()) -> 哈希表数组下标
- 有一点需要注意：由于散列冲突的客观存在，哈希表中各节点通常需要保存key-value对，用以作key的比较

### 10.1 散列函数

要求：
1. 散列值为非负整数（这样才可以作为数组下标）
2. 若key1=key2，那么hash(key1) = hash(key2)
3. 若key1 != key2，那么hash(key1) != hash(key2)

第3点无法保证，客观上必然存在散列冲突

### 10.2 散列冲突的解决

装载因子表示哈希表空位还有多少：

```
装载因子 = 填入的元素个数 / 散列表数组长度
```

装载因子越大，说明空位越少，冲突越多，哈希表性能会下降

1. 开放寻址法
    - 线性探测法
        - 插入时若碰撞，则线性向后探测可用位置
        - 查找时若该位置存在节点则检查key是否匹配，不匹配说明发生冲突，线性向后查找
        - 删除。标记为删除即可
    - 二次探测法
        - 探测序列不再是线性探测的`hash(key), hash(key)+1, hash(key)+2, ...`，而是`hash(key), hash(key)+1^2, hash(key)+2^2, ...`
    - 双重散列法
        - 使用两个或多个散列函数。当hash1(key)冲突，继续使用hash2(key)，... 直至找到可用位置
2. 拉链法
    - 冲突了就往后边拉条链表
    - 其实也可以往后边拉数组
    - 链表长度过长可以转换成红黑树、跳表等 

### 10.3 工业级散列表的实现

- 散列表设计不好，或装载因子过高。就会导致散列冲突概率升高，查询效率下降
- 散列表碰撞攻击： 例如，对于拉链式散列表，大量请求插入某一个桶的拉链，使得拉链很长，这样服务器CPU大量消耗在拉链插入上，无法响应其他请求，达到拒绝服务攻击（DoS）的目的

1. 散列函数设计
    - 不能太复杂，性能要高
    - 散列值 随机、均匀分布
    - 常用的散列方法：取模、直接寻址、平方取中、折叠法、随机数法、...
2. 装载因子过大时解决
    - 动态扩容以降低装载因子
        - 渐进式扩容，避免一次性扩容消耗过长时间
    - 内存敏感时还要考虑动态缩容
    - 装载因子阈值的设置需要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。
3. 冲突解决办法选择
    - 开放寻址法
        - 优点：基于数组，有效利用CPU缓存机制；序列化简单
        - 缺点：删除数据较麻烦，需特殊标记； 冲突代价更高，因此装载因子阈值不能太大，更浪费内存空间；
        - 数据量较小、装载因子小时适合开放寻址法。
        - 典例：Java ThreadLocalMap
    - 拉链法
        - 优点：内存利用率更高，链表节点可以在需要时再创建； 对大装载因子容忍度更高； 可以使用红黑树、跳表替代链表来进行优化
        - 缺点：额外存储链表节点指针，当存小对象时该内存占用不可忽视； 不利于CPU缓存，对执行效率有一定影响
        - 适合存储大对象、大数据量。
        - 典例：Java LinkedHashMap

- Java HashMap举例
    - 默认初始大小16
    - 默认装载因子阈值0.75
    - 动态扩容因子 2
    - 拉链法解决冲突
    - 拉链长度超过8(默认)，链表转换为红黑树；红黑树节点数小于8，转换为链表
    - 散列函数设计。利用Object的hashCode()方法得哈希码，再通过一个转换过程去计算散列值。具体自行参考

### 10.4 散列表 + 双向链表

- 散列表增删改查操作快 O(1), 但是无序
- 双向链表支持有序，但是操作慢

典型案例：
- LRU缓存
- Redis有序集合
- Java LinkedHashMap

## 11. 哈希算法

哈希算法要求：

- 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
- 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小； （根据鸽巢原理/抽屉原理，冲突必然存在）
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

哈希算法应用：

1. 安全加密
    - 存储密码时不存明文，而存哈希值
    - 为应对暴力匹配，还可以加盐再哈希，甚至还会使用执行速度很慢的哈希算法来增加暴力匹配的成本。
2. 唯一标识
    - 为图库中每张图片生成id
    - 若id冲突，再比较图片本身
3. 数据校验
    - BT下载大文件，分块传输，为每个块生成哈希值，以校验某些块数据是否完整正确，及时重传   
    - 块的哈希值存储于种子文件中     
4. 散列函数
    - 散列函数对是否反向破解不关心，也不要求极低的碰撞率
    - 散列函数要求性能高、散列值均匀分布
5. 负载均衡
    - 负载均衡算法有：轮询、随机、加权轮询等
    - 如何实现**会话粘滞**的负载均衡？
        - 维护 会话ID->服务器ID 的映射表。 缺点：映射表可能很大；客户端上下线、服务器扩容缩容都会导致映射失效，映射表维护成本高
        - 利用哈希算法。根据会话ID或客户端ID等信息取哈希值，哈希值再对服务器列表大小取模，映射得服务器ID
6. 数据分片
7. 分布式存储

- 分布式中普通哈希算法的优化：
    - 一致性哈希（关键词：哈希环解决集群扩缩容时数据重哈希问题、数据偏移问题、缓存/存储雪崩问题、虚拟节点解决数据偏移）


## 12. 二叉树

### 12.1 树

- 树
    - 二叉树
        - 满二叉树
        - 完全二叉树
        - 非完全二叉树
    - 多叉树

- 完全二叉树
    - 要求：
        - 叶子节点在最后两层
        - 最后一层叶子节点全部靠左排列
        - 除最后一层，其它层满节点
    - 优点：
        - 适合数组存储
        - 以数组下标1起始，当前节点`p`的下标为`i`， 则`p`的左右子节点下标分别为`2i`, `2i+1`， 父节点下标`i/2`        
- 树的遍历
    - 前序遍历（中左右）
    - 中序遍历（左中右）  
    - 后序遍历（左右中）     
    - 层序遍历
    - 莫里斯遍历（自行搜索）

### 12.2 二叉查找树

- 要求：
    - 任意节点，其左子树节点的值均小于该节点值； 其右子树节点的值均大于该节点值
- 查找：
    1. `if target == cur.val`, 返回cur
    2. `if target < cur.val` 去左子树找，否则去右子树找
- 插入：
    1. `if target > cur.val`
        - `if cur.right == nil` 将target插在cur.right
        - 否则，继续往`cur.right`子树插入
    2. `if target < cur.val` 类似
- 删除
    1. 查找到待删节点`p`
    2. 根据`p`的三种情况讨论：
        1. `p`是叶子节点，直接删除，将其父节点指向`p`的指针置为nil
        2. `p`只有一个子节点，将`p`父节点指向`p`的指针改指向p的后继节点     
        3. `p`有两个子节点。需要找到后继节点(可以是`p.right`子树中最小节点，也可以是`p.left`子树最大节点，这里取右子树最小节点作为后继)
            1. 找到右子树最小节点`rightMin`，一路往右子树的最左边往下找就是
            2. 把`rightMin`的值赋给`p`   
            3. 在`p.right`子树中删除`rightMin`节点
    - 删除还有个取巧办法：不删，而是只作`deleted`标记 
- 输出有序序列： 中序遍历
- 支持重复数据的二叉查找树。
    - 一种做法是把值相等的数据放在一个节点里
    - 另一种是允许相同数据的节点（如果遇到重复值的节点， 统一规定插在左边或右边） 
- 时间复杂度 O(h)，h为树高。树平衡时 h=logn

### 12.3 红黑树

- 平衡二叉查找树的严格要求是：任何节点的左右子树高度相差不超过1
- AVL树是最早的
- 红黑树根节点到叶节点的最长路径可能比最短路径长一倍，是“近似平衡”的

红黑树的要求：
- 节点有颜色标记，红或黑
- 根节点是黑色的；
- 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；（这是为了实现方便）
- 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；（也就是“完美的黑色平衡”）

红黑树的实现自行查阅，也可参考：
<https://eiger.me/post/algo/search/#3-%E7%BA%A2%E9%BB%91%E6%A0%91>

### 12.4 递归树分析递归算法的时间复杂度

- 有些代码比较适合用递推公式来分析，比如归并排序的时间复杂度、快速排序的最好情况时间复杂度；
- 有些比较适合采用递归树来分析，比如快速排序的平均时间复杂度。
- 而有些可能两个都不怎么适合使用，比如二叉树的递归前中后序遍历。

## 13. 堆与堆排序



